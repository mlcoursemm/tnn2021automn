{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practice01.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X2GPoeVHUVTq"},"source":["# Практическое задание 1\r\n","\r\n","## Данные о студенте\r\n","\r\n","1. **ФИО**: ххх\r\n","2. **Факультет**: ххх\r\n","3. **Курс**: ххх\r\n","4. **Группа**: ххх\r\n","\r\n","## Замечания\r\n","\r\n","* Название ноутбука с реализацией должно иметь шаблон \"**Prac01_Ivanov.ipynb**\" и посылаться на почту mlcoursemm@gmail.com с темой **[CV2021:Prac01]**\r\n","* Дедлайн будет оговорен в чате курса\r\n","* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\r\n","* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\r\n","* Ничего, крому Numpy, нельзя использовать для реализации \r\n","* **Keras** используется только для тестирования Вашей реализации\r\n","* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\r\n","* Возможно использование дополнительных (приватных) тестов\r\n"," "]},{"cell_type":"code","metadata":{"id":"hT1dNA7Gb35a"},"source":["# Вам понадобится для реализации\r\n","import numpy as np\r\n","# Нужно для тестирования\r\n","from tensorflow import keras\r\n","import keras.layers as layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0G7sQn2ZXh9Y"},"source":["* Вспомогательные функции для тестирования"]},{"cell_type":"code","metadata":{"id":"_vXhfmihINmY"},"source":["def compare_tensors(x, y, tol=0.001, test_name='Test'):\r\n","  assert (x.shape == y.shape), test_name + ' different shapes'\r\n","  diff = np.sum((y - x)**2)\r\n","  assert (diff < tol), test_name + ' Failed!'\r\n","  print (test_name + ' Passed!')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pq_lVMUle_ii"},"source":["def compare_tensors_array(x, y, tol=0.001, test_name='Test'):\r\n","  assert (len(x) == len(y)), test_name + ' different lengths'\r\n","  for i in range(len(x)):\r\n","    t = test_name + ' subtest ' + str(i)\r\n","    compare_tensors(x[i], y[i], tol=tol, test_name=t)\r\n","  print (test_name + ' Passed!')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4iNYGlDyNAF"},"source":["* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"]},{"cell_type":"code","metadata":{"id":"05lYhmjMSm0s"},"source":["class Layer(object):\r\n","    def __init__(self):\r\n","        self.name = 'Layer'       \r\n","    def forward(self, input_data):\r\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caE-Xn1ZY79p"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"R9yuQiPjyOBZ"},"source":["* (1 балл) Реализация \"спрямляющего\" слоя Flatten"]},{"cell_type":"code","metadata":{"id":"zJIqDFDC-8Gh"},"source":["class FlattenLayer(Layer):\r\n","    def __init__(self):\r\n","      self.name = 'Flatten'\r\n","    def forward(self, input_data):\r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\r\n","      # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vAD92fJkYcNI"},"source":["* Функция предварительного тестирования слоя **Flatten**\r\n","* Функции с названием \"**test_**\" не менять\r\n","* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"]},{"cell_type":"code","metadata":{"id":"eZsoCXd1HioL"},"source":["def test_FlattenLayer():\r\n","  B = 1\r\n","  C = 1\r\n","  H = 3\r\n","  W = 3\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.Flatten(data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = FlattenLayer().forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 1')\r\n","  B = 1\r\n","  C = 2\r\n","  H = 3\r\n","  W = 3\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.Flatten(data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = FlattenLayer().forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 2')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eMe7eba6Yu4a"},"source":["* Запуск теста слоя Flatten\r\n","* Нужно, чтобы все тесты были '*Passed!*'"]},{"cell_type":"code","metadata":{"id":"pST9EihGKTEh"},"source":["test_FlattenLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOngWlbqyQJ9"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"q6NfaNFKZGOk"},"source":["* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"]},{"cell_type":"code","metadata":{"id":"1d3U8gE1-8J1"},"source":["class GAP2DLayer(Layer):\r\n","    def __init__(self):\r\n","      self.name = 'GAP2D'\r\n","    def forward(self, input_data):\r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9KLCdrTLT-j"},"source":["def test_GAP2DLayer():\r\n","  B = 1\r\n","  C = 1\r\n","  H = 3\r\n","  W = 3\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.GlobalAveragePooling2D(data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = GAP2DLayer().forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 1')\r\n","  B = 1\r\n","  C = 2\r\n","  H = 3\r\n","  W = 3\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.GlobalAveragePooling2D(data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = GAP2DLayer().forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 2')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbuDxhloPLKs"},"source":["test_GAP2DLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nbse3gb2ySI_"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"l2CCmuiZZTXp"},"source":["* (2 балла) Реализация слоя субдискретизации **MaxPooling**"]},{"cell_type":"code","metadata":{"id":"fFSW6Xpp-8NS"},"source":["class MaxPool2DLayer(Layer):\r\n","    def __init__(self, pool_size=2, stride=2):\r\n","      self.name = 'MaxPool2D'\r\n","      self.pool_size = pool_size\r\n","      self.stride = stride\r\n","    def forward(self, input_data):\r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvCIn_aXUPkD"},"source":["def test_MaxPool2DLayer():\r\n","  B = 1\r\n","  C = 1\r\n","  H = 4\r\n","  W = 4\r\n","  pool_size = 2\r\n","  stride = 2\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 1')\r\n","  B = 2\r\n","  C = 2\r\n","  H = 3\r\n","  W = 3\r\n","  pool_size = 2\r\n","  stride = 1  \r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\r\n","  y_keras = y(x).numpy()\r\n","  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 2')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHRtvEIpVsYe"},"source":["test_MaxPool2DLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLtOD86byTQ-"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"zruUuHDeZf-4"},"source":["* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"]},{"cell_type":"code","metadata":{"id":"yFytq6FOByQ9"},"source":["class ActivationLayer(Layer):\r\n","    def __init__(self, activation='relu'):\r\n","      # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\r\n","      self.name = 'Activation'\r\n","      self.activation = activation\r\n","    def forward(self, input_data):   \r\n","      # На входе:\r\n","      # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\r\n","      # или двухмерный тензор вида [batch, logits]\r\n","      # SoftMax применяется по последней размерности\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RnOBuLTWcIf"},"source":["def test_ActivationLayer():\r\n","  B = 1\r\n","  C = 1\r\n","  H = 4\r\n","  W = 4\r\n","  activation = 'relu'\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.Activation(activation)\r\n","  y_keras = y(x).numpy()\r\n","  y_out = ActivationLayer(activation=activation).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 1')\r\n","  B = 2\r\n","  C = 2\r\n","  H = 3\r\n","  W = 3\r\n","  activation = 'sigmoid'  \r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.Activation(activation)\r\n","  y_keras = y(x).numpy()\r\n","  y_out = ActivationLayer(activation=activation).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 2')\r\n","  B = 3\r\n","  C = 10\r\n","  activation = 'softmax'\r\n","  x = np.random.randn(B, C)\r\n","  y = layers.Activation(activation)\r\n","  y_keras = y(x).numpy()\r\n","  y_out = ActivationLayer(activation=activation).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 3')  \r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3Bwcpw7X4_m"},"source":["test_ActivationLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5YtW9jiayUdV"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"7dOJl776Z0t7"},"source":["* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"]},{"cell_type":"code","metadata":{"id":"0-bCGIE--8QH"},"source":["# Hint\r\n","# Train mode:\r\n","# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\r\n","# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\r\n","# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\r\n","# Test mode:\r\n","# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\r\n","\r\n","class BatchNormLayer(Layer):\r\n","    def __init__(self, momentum=0.99, epsilon=0.001, beta_init=None, gamma_init=None,\r\n","                 moving_mean_init=None, moving_var_init=None,\r\n","                 mode='train', input_channels=2):\r\n","      # mode: 'train', 'test'\r\n","      # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels   \r\n","      self.name = 'BatchNorm'\r\n","      self.momentum = momentum\r\n","      self.epsilon = epsilon\r\n","      self.beta = beta_init\r\n","      self.gamma = gamma_init\r\n","      self.moving_mean = moving_mean_init\r\n","      self.moving_var = moving_var_init\r\n","      self.mode = mode\r\n","      self.input_channels = input_channels\r\n","    def forward(self, input_data):   \r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\r\n","      # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhZ6TK-RYfm-"},"source":["def test_BatchNormLayer():\r\n","  B = 2\r\n","  C = 2\r\n","  H = 4\r\n","  W = 4\r\n","  beta_init = 0 * np.ones(C)\r\n","  gamma_init = 1 * np.ones(C)\r\n","  moving_mean_init = 0 * np.ones(C)\r\n","  moving_var_init= 1 * np.ones(C)\r\n","  momentum = 0.99\r\n","  epsilon = 0.001\r\n","  mode = 'train'\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=True)\r\n","  y_keras = y(x, training=True).numpy()\r\n","  y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\r\n","  y_keras = y(x, training=True).numpy()\r\n","  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\r\n","                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\r\n","                 mode=mode, input_channels=C)\r\n","  y_out = y_out_layer.forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 1')\r\n","  compare_tensors_array(y.get_weights(), \r\n","                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\r\n","                        tol=0.00001, test_name='Test BatchNorm 1.1')\r\n","  B = 2 \r\n","  C = 2 \r\n","  H = 4 \r\n","  W = 4 \r\n","  beta_init = 1 * np.ones(C)\r\n","  gamma_init = 0 * np.ones(C)\r\n","  moving_mean = 0 * np.ones(C)\r\n","  moving_var = 1 * np.ones(C)\r\n","  momentum = 0.99\r\n","  epsilon = 0.001\r\n","  mode = 'test'\r\n","  x = np.random.randn(B, C, H, W)\r\n","  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=False)\r\n","  y_keras = y(x, training=False).numpy()\r\n","  y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\r\n","  y_keras = y(x, training=False).numpy()\r\n","  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\r\n","                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\r\n","                 mode=mode, input_channels=C)\r\n","  y_out = y_out_layer.forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 2')  \r\n","  compare_tensors_array(y.get_weights(), \r\n","                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\r\n","                        tol=0.00001, test_name='Test BatchNorm 2.1')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZ2F0Xg1Yf94"},"source":["test_BatchNormLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fJKt_4mCyV4r"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"-f_m9DaTaHio"},"source":["* (1 балл) Реализация **полносвязного** слоя"]},{"cell_type":"code","metadata":{"id":"1Ln22ERp8mC5"},"source":["class DenseLayer(Layer):\r\n","    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\r\n","      self.name = 'Dense'\r\n","      self.input_dim = input_dim\r\n","      self.output_dim = output_dim\r\n","      self.W = W_init\r\n","      self.b = b_init\r\n","    def forward(self, input_data):\r\n","      # На входе - двухмерный тензор вида [batch, input_channels]\r\n","      # Работаем по второй размерности, по первой размерности НЕ преобразуем\r\n","      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ln9JIKL8YhZF"},"source":["def test_DenseLayer():\r\n","  B = 1\r\n","  C_IN = 10\r\n","  C_OUT = 5\r\n","  x = np.random.randn(B, C_IN)\r\n","  W_init = np.random.randn(C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Dense(C_OUT, use_bias=True)\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([W_init, b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 1')\r\n","  B = 2\r\n","  C_IN = 5\r\n","  C_OUT = 10\r\n","  x = np.random.randn(B, C_IN)\r\n","  W_init = np.random.randn(C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([W_init, b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 2')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NA_KNjZYhec"},"source":["test_DenseLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"966wyQwryXun"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"j6A8OLysaS3Q"},"source":["* (2 балла) Реализация **сверточного** слоя"]},{"cell_type":"code","metadata":{"id":"quhEATTW9jyK"},"source":["class Conv2DLayer(Layer):\r\n","    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \r\n","                 padding='same', stride=1, K_init=None, b_init=None):\r\n","      # padding: 'same' или 'valid'\r\n","      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\r\n","      # Работаем с единообразным сдвигом, поэтому stride - одно число\r\n","      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\r\n","      self.name = 'Conv2D'\r\n","      self.kernel_size = kernel_size\r\n","      self.input_channels = input_channels\r\n","      self.output_channels = output_channels\r\n","      self.kernel = K_init\r\n","      self.bias = b_init\r\n","      self.padding = padding\r\n","      self.stride = stride\r\n","    def forward(self, input_data):\r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUA1PbOBYiH3"},"source":["def test_Conv2DLayer():\r\n","  B = 1\r\n","  C_IN = 1\r\n","  C_OUT = 1\r\n","  H = 10\r\n","  W = 10\r\n","  K = 3\r\n","  S = 1\r\n","  padding = 'same'\r\n","  x = np.random.randn(B, C_IN, H, W)\r\n","  K_init = np.random.randn(K, K, C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\r\n","    dilation_rate=1, groups=1, activation=None, use_bias=True)\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([K_init, b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \r\n","                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\r\n","  B = 2\r\n","  C_IN = 3\r\n","  C_OUT = 5\r\n","  H = 9\r\n","  W = 9\r\n","  K = 3\r\n","  S = 2\r\n","  padding = 'valid'\r\n","  x = np.random.randn(B, C_IN, H, W)\r\n","  K_init = np.random.randn(K, K, C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\r\n","    dilation_rate=1, groups=1, activation=None, use_bias=True, input_shape=(C_IN, H, W))\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([K_init, b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \r\n","                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZI5iUu4YiOD"},"source":["test_Conv2DLayer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"91-bDvSvyY2e"},"source":["\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"1hPqOr5zad6H"},"source":["* (2 балла) Реализация **транспонированного сверточного** слоя"]},{"cell_type":"code","metadata":{"id":"97D7QOwm-ER1"},"source":["class Conv2DTrLayer(Layer):\r\n","    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \r\n","                 padding=0, stride=1, K_init=None, b_init=None):      \r\n","      # padding: число (сколько отрезать от модифицированной входной карты)\r\n","      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\r\n","      # stride - одно число (коэффициент расширения)\r\n","      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\r\n","      self.name = 'Conv2DTr'\r\n","      self.kernel_size = kernel_size\r\n","      self.input_channels = input_channels\r\n","      self.output_channels = output_channels\r\n","      self.kernel = K_init\r\n","      self.bias = b_init\r\n","      self.padding = padding\r\n","      self.stride = stride\r\n","    def forward(self, input_data):\r\n","      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\r\n","      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\r\n","      # Нужно заполнить Numpy-тензор out \r\n","      out = np.empty([])\r\n","      return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueU3lS9-Yi8t"},"source":["def adjust_kernel(K):\r\n","  K_new = K.copy()[::-1, ::-1, :, :]\r\n","  K_new = np.transpose(K_new, (0, 1, 3, 2))\r\n","  return K_new\r\n","\r\n","def test_Conv2DTrLayer():\r\n","  B = 1\r\n","  C_IN = 1\r\n","  C_OUT = 1\r\n","  H = 3\r\n","  W = 3\r\n","  K = 3\r\n","  S = 2\r\n","  padding = 0\r\n","  x = np.random.randn(B, C_IN, H, W)\r\n","  K_init = np.random.randn(K, K, C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \r\n","                    data_format='channels_first', dilation_rate=1, groups=1, \r\n","                    activation=None, use_bias=True)\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([adjust_kernel(K_init), b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \r\n","                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 1')\r\n","  B = 4\r\n","  C_IN = 2\r\n","  C_OUT = 3\r\n","  H = 3\r\n","  W = 3\r\n","  K = 3\r\n","  S = 2\r\n","  padding = 0\r\n","  x = np.random.randn(B, C_IN, H, W)\r\n","  K_init = np.random.randn(K, K, C_IN, C_OUT)\r\n","  b_init = np.random.randn(C_OUT)\r\n","  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \r\n","                    data_format='channels_first', dilation_rate=1, groups=1, \r\n","                    activation=None, use_bias=True)\r\n","  y_keras = y(x).numpy()\r\n","  y.set_weights([adjust_kernel(K_init), b_init])\r\n","  y_keras = y(x).numpy()\r\n","  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \r\n","                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\r\n","  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 2')\r\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rW2REQR3-6dd"},"source":["test_Conv2DTrLayer()"],"execution_count":null,"outputs":[]}]}