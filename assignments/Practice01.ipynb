{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2GPoeVHUVTq"
   },
   "source": [
    "# Практическое задание 1\n",
    "\n",
    "\n",
    "\n",
    "## Замечания\n",
    "* Задание необходимо сдать боту до 15.11.2021\n",
    "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
    "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
    "* Ничего, крому Numpy, нельзя использовать для реализации \n",
    "* **Keras** используется только для тестирования Вашей реализации\n",
    "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
    "* Возможно использование дополнительных (приватных) тестов\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT1dNA7Gb35a"
   },
   "outputs": [],
   "source": [
    "# Вам понадобится для реализации\n",
    "import numpy as np\n",
    "# Нужно для тестирования\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G7sQn2ZXh9Y"
   },
   "source": [
    "* Вспомогательные функции для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vXhfmihINmY"
   },
   "outputs": [],
   "source": [
    "def compare_tensors(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (x.shape == y.shape), test_name + ' different shapes'\n",
    "  diff = np.sum((y - x)**2)\n",
    "  assert (diff < tol), test_name + ' Failed!'\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq_lVMUle_ii"
   },
   "outputs": [],
   "source": [
    "def compare_tensors_array(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (len(x) == len(y)), test_name + ' different lengths'\n",
    "  for i in range(len(x)):\n",
    "    t = test_name + ' subtest ' + str(i)\n",
    "    compare_tensors(x[i], y[i], tol=tol, test_name=t)\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4iNYGlDyNAF"
   },
   "source": [
    "* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05lYhmjMSm0s"
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'Layer'       \n",
    "    def forward(self, input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caE-Xn1ZY79p"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9yuQiPjyOBZ"
   },
   "source": [
    "* (1 балл) Реализация \"спрямляющего\" слоя Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJIqDFDC-8Gh"
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'Flatten'\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\n",
    "      # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAD92fJkYcNI"
   },
   "source": [
    "* Функция предварительного тестирования слоя **Flatten**\n",
    "* Функции с названием \"**test_**\" не менять\n",
    "* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZsoCXd1HioL"
   },
   "outputs": [],
   "source": [
    "def test_FlattenLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMe7eba6Yu4a"
   },
   "source": [
    "* Запуск теста слоя Flatten\n",
    "* Нужно, чтобы все тесты были '*Passed!*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pST9EihGKTEh"
   },
   "outputs": [],
   "source": [
    "test_FlattenLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOngWlbqyQJ9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NfaNFKZGOk"
   },
   "source": [
    "* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d3U8gE1-8J1"
   },
   "outputs": [],
   "source": [
    "class GAP2DLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'GAP2D'\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9KLCdrTLT-j"
   },
   "outputs": [],
   "source": [
    "def test_GAP2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbuDxhloPLKs"
   },
   "outputs": [],
   "source": [
    "test_GAP2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbse3gb2ySI_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2CCmuiZZTXp"
   },
   "source": [
    "* (2 балла) Реализация слоя субдискретизации **MaxPooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFSW6Xpp-8NS"
   },
   "outputs": [],
   "source": [
    "class MaxPool2DLayer(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "      self.name = 'MaxPool2D'\n",
    "      self.pool_size = pool_size\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvCIn_aXUPkD"
   },
   "outputs": [],
   "source": [
    "def test_MaxPool2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  pool_size = 2\n",
    "  stride = 2\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  pool_size = 2\n",
    "  stride = 1  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHRtvEIpVsYe"
   },
   "outputs": [],
   "source": [
    "test_MaxPool2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLtOD86byTQ-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zruUuHDeZf-4"
   },
   "source": [
    "* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFytq6FOByQ9"
   },
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation='relu'):\n",
    "      # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\n",
    "      self.name = 'Activation'\n",
    "      self.activation = activation\n",
    "    def forward(self, input_data):   \n",
    "      # На входе:\n",
    "      # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\n",
    "      # или двухмерный тензор вида [batch, logits]\n",
    "      # SoftMax применяется по последней размерности\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RnOBuLTWcIf"
   },
   "outputs": [],
   "source": [
    "def test_ActivationLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  activation = 'relu'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  activation = 'sigmoid'  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 2')\n",
    "  B = 3\n",
    "  C = 10\n",
    "  activation = 'softmax'\n",
    "  x = np.random.randn(B, C)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 3')  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3Bwcpw7X4_m"
   },
   "outputs": [],
   "source": [
    "test_ActivationLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YtW9jiayUdV"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dOJl776Z0t7"
   },
   "source": [
    "* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-bCGIE--8QH"
   },
   "outputs": [],
   "source": [
    "# Hint\n",
    "# Train mode:\n",
    "# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\n",
    "# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
    "# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\n",
    "# Test mode:\n",
    "# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, momentum=0.99, epsilon=0.001, beta_init=None, gamma_init=None,\n",
    "                 moving_mean_init=None, moving_var_init=None,\n",
    "                 mode='train', input_channels=2):\n",
    "      # mode: 'train', 'test'\n",
    "      # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels   \n",
    "      self.name = 'BatchNorm'\n",
    "      self.momentum = momentum\n",
    "      self.epsilon = epsilon\n",
    "      self.beta = beta_init\n",
    "      self.gamma = gamma_init\n",
    "      self.moving_mean = moving_mean_init\n",
    "      self.moving_var = moving_var_init\n",
    "      self.mode = mode\n",
    "      self.input_channels = input_channels\n",
    "    def forward(self, input_data):   \n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\n",
    "      # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhZ6TK-RYfm-"
   },
   "outputs": [],
   "source": [
    "def test_BatchNormLayer():\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 4\n",
    "  W = 4\n",
    "  beta_init = 0 * np.ones(C)\n",
    "  gamma_init = 1 * np.ones(C)\n",
    "  moving_mean_init = 0 * np.ones(C)\n",
    "  moving_var_init= 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'train'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=True)\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 1')\n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 1.1')\n",
    "  B = 2 \n",
    "  C = 2 \n",
    "  H = 4 \n",
    "  W = 4 \n",
    "  beta_init = 1 * np.ones(C)\n",
    "  gamma_init = 0 * np.ones(C)\n",
    "  moving_mean = 0 * np.ones(C)\n",
    "  moving_var = 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'test'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=False)\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 2')  \n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 2.1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ2F0Xg1Yf94"
   },
   "outputs": [],
   "source": [
    "test_BatchNormLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJKt_4mCyV4r"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f_m9DaTaHio"
   },
   "source": [
    "* (1 балл) Реализация **полносвязного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ln22ERp8mC5"
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
    "      self.name = 'Dense'\n",
    "      self.input_dim = input_dim\n",
    "      self.output_dim = output_dim\n",
    "      self.W = W_init\n",
    "      self.b = b_init\n",
    "    def forward(self, input_data):\n",
    "      # На входе - двухмерный тензор вида [batch, input_channels]\n",
    "      # Работаем по второй размерности, по первой размерности НЕ преобразуем\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ln9JIKL8YhZF"
   },
   "outputs": [],
   "source": [
    "def test_DenseLayer():\n",
    "  B = 1\n",
    "  C_IN = 10\n",
    "  C_OUT = 5\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 1')\n",
    "  B = 2\n",
    "  C_IN = 5\n",
    "  C_OUT = 10\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NA_KNjZYhec"
   },
   "outputs": [],
   "source": [
    "test_DenseLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966wyQwryXun"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6A8OLysaS3Q"
   },
   "source": [
    "* (2 балла) Реализация **сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quhEATTW9jyK"
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding='same', stride=1, K_init=None, b_init=None):\n",
    "      # padding: 'same' или 'valid'\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2D'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUA1PbOBYiH3"
   },
   "outputs": [],
   "source": [
    "def test_Conv2DLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 10\n",
    "  W = 10\n",
    "  K = 3\n",
    "  S = 1\n",
    "  padding = 'same'\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([K_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "  B = 2\n",
    "  C_IN = 3\n",
    "  C_OUT = 5\n",
    "  H = 9\n",
    "  W = 9\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 'valid'\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True, input_shape=(C_IN, H, W))\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([K_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZI5iUu4YiOD"
   },
   "outputs": [],
   "source": [
    "test_Conv2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91-bDvSvyY2e"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hPqOr5zad6H"
   },
   "source": [
    "* (2 балла) Реализация **транспонированного сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97D7QOwm-ER1"
   },
   "outputs": [],
   "source": [
    "class Conv2DTrLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding=0, stride=1, K_init=None, b_init=None):      \n",
    "      # padding: число (сколько отрезать от модифицированной входной карты)\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # stride - одно число (коэффициент расширения)\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2DTr'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueU3lS9-Yi8t"
   },
   "outputs": [],
   "source": [
    "def adjust_kernel(K):\n",
    "  K_new = K.copy()[::-1, ::-1, :, :]\n",
    "  K_new = np.transpose(K_new, (0, 1, 3, 2))\n",
    "  return K_new\n",
    "\n",
    "def test_Conv2DTrLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 1')\n",
    "  B = 4\n",
    "  C_IN = 2\n",
    "  C_OUT = 3\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rW2REQR3-6dd"
   },
   "outputs": [],
   "source": [
    "test_Conv2DTrLayer()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
